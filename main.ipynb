{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **CS282br Final Project**\n",
    "Varshini Reddy,\n",
    "Michael Cheng,\n",
    "Matthew Nazari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import pickle\n",
    "import pandas as pd\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "# import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Datasets**\n",
    "1. Cost $\\in 13226 \\times 2$\n",
    "2. Pneumonia $\\in 5856 \\times 13228$\n",
    "3. Pneumonia base $\\in 1171 \\times 13228$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets\n",
    "dfs = dict(\n",
    "  # pneumonia=pd.read_csv('data/pneumonia.csv', low_memory=False),\n",
    "  # pneumonia_base=pd.read_csv('data/pneumonia_base_train.csv'),\n",
    "  # unbalanced=pd.read_csv('data/total_data.csv'),\n",
    "  balanced=pd.read_csv('data/balanced_data.csv'),\n",
    "  cost=pd.read_csv('data/cost.csv'),\n",
    "  mean_features=pd.read_csv('data/mean_features.csv'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe utilites\n",
    "\n",
    "## split a dataframe into x_train and y_train for logistic regression\n",
    "def datafy (x: pd.DataFrame, y: pd.DataFrame):\n",
    "  return x.values, y.values.ravel()\n",
    "\n",
    "def split_df(df: pd.DataFrame, ignore_cols: list[str] = [], ret_df: bool = True):\n",
    "  kept_cols = df.columns != 'class'\n",
    "  for c in ignore_cols:\n",
    "    kept_cols &= (df.columns != c)\n",
    "  x, y = df.loc[:, kept_cols], df.loc[:, df.columns == 'class']\n",
    "  return (x, y) if ret_df else datafy(x, y)\n",
    "\n",
    "def random_rows(x: np.ndarray, y: np.ndarray, p: float):\n",
    "  assert 0 <= p <= 1, \"random_rows: invalid percentage\"\n",
    "  assert x.shape[0] == y.shape[0], \"random_rows: x.shape[0] != y.shape[0]\"\n",
    "  idxs = npr.choice(x.shape[0], int(x.shape[0]*p), replace=False)\n",
    "  return x[idxs, :], y[idxs]\n",
    "\n",
    "# def logreg_score(x: np.ndarray, y: np.ndarray, p: float = 0.05):\n",
    "#   x_train, y_train = random_rows(x, y, p)\n",
    "#   lr = LogisticRegression().fit(x_train, y_train)\n",
    "#   return lr.score(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rewards**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthew/Desktop/cs282br-project/venv/lib/python3.9/site-packages/sklearn/base.py:324: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.23.2 when using version 1.0.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def get_updated_data(df: pd.DataFrame, features: list[str]):\n",
    "    df = df.copy()\n",
    "    for f in features:\n",
    "        df[f] = dfs['mean_features'][f].item()            \n",
    "    return df\n",
    "\n",
    "lr_filename=\"data/logistic_model.sav\"\n",
    "lr_model = pickle.load(open(lr_filename, 'rb'))\n",
    "\n",
    "def get_reward(features, df, model=lr_model):\n",
    "    x, y = split_df(df)\n",
    "    x = get_updated_data(x, features)\n",
    "    x, y = datafy(x, y)\n",
    "    y_pred = model.predict(x)\n",
    "    reward = accuracy_score(y, y_pred)\n",
    "    scale = 0.05\n",
    "    cost = dfs['cost'][features].values.sum()**scale\n",
    "\n",
    "    return (reward*100)/cost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Selection Algorithms**\n",
    "- All features\n",
    "- Random drop 50%\n",
    "- Random drop 75%\n",
    "- CMAB-GFS [(epubs.siam.org/doi/pdf/10.1137/1.9781611976700.36)](https://epubs.siam.org/doi/pdf/10.1137/1.9781611976700.36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection Algorithms\n",
    "\n",
    "## All features\n",
    "all_features = lambda df: split_df(df)[0].columns\n",
    "\n",
    "## Random drop 50% and 75%\n",
    "def random_drop(df: pd.DataFrame, p: float):\n",
    "  assert 0 <= p <= 1, \"random_drop: invalid percentage\"\n",
    "  x, _ = split_df(df)\n",
    "  return npr.choice(x.columns, x.shape[0]*p)\n",
    "\n",
    "random_drop_50 = lambda df: random_drop(df, 0.50)\n",
    "random_drop_75 = lambda df: random_drop(df, 0.75)\n",
    "\n",
    "## CMAB-GFS\n",
    "def generative_oracle (M, K, betas, eps):\n",
    "  if npr.rand() < eps:\n",
    "    return npr.choice(M, K)\n",
    "  else:\n",
    "    samples = {c: npr.beta(*params) for c, params in betas.items()}\n",
    "    return [k for k, _ in sorted(samples.items(), key=lambda item: item[1], reverse=True)][:K]\n",
    "\n",
    "def cmab_gfs(df, K, T, R, eps):\n",
    "  assert 0 <= eps <= 1, \"cmab_gfs: eps must be in [0, 1]\"\n",
    "  x, _ = split_df(df)\n",
    "  M = x.columns\n",
    "  betas = {c: (0.5, 0.5) for c in M}\n",
    "  S_old = npr.choice(M, K)\n",
    "  r_old = R(S_old)\n",
    "  history = []\n",
    "  for _ in tqdm(range(T)):\n",
    "    history.append(r_old)\n",
    "    S_new = generative_oracle(M, K, betas, eps)\n",
    "    r_new = R(S_new)\n",
    "    for i in np.union1d(S_old, S_new):\n",
    "      a, b = betas[i]\n",
    "      betas[i] = (a+1, b) if r_new > r_old else (a, b+1)\n",
    "    S_old, r_old = S_new, r_new\n",
    "    history.append(dict(features=S_new, reward=r_new))\n",
    "  return S_new, history\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [20:27<00:00,  2.46s/it]\n",
      "100%|██████████| 500/500 [22:56<00:00,  2.75s/it]\n",
      "100%|██████████| 500/500 [25:18<00:00,  3.04s/it]\n",
      "100%|██████████| 500/500 [23:57<00:00,  2.88s/it]\n",
      "100%|██████████| 500/500 [23:49<00:00,  2.86s/it]\n",
      "100%|██████████| 500/500 [24:25<00:00,  2.93s/it]\n",
      "100%|██████████| 500/500 [25:05<00:00,  3.01s/it]\n",
      "100%|██████████| 500/500 [26:19<00:00,  3.16s/it]\n",
      " 59%|█████▊    | 293/500 [15:01<10:58,  3.18s/it]"
     ]
    }
   ],
   "source": [
    "# Run CMAB-GFS algorithm for 10% .. 100% of features and save to './results/'\n",
    "df = dfs['balanced']\n",
    "x, _ = split_df(df)\n",
    "total_features = len(x.columns)\n",
    "for i in range(1, 11):\n",
    "  K = int(i/10 * total_features)\n",
    "  _, history = cmab_gfs(df, K=K, T=500, R=lambda f: get_reward(f, df), eps=0.10)\n",
    "  with open(f'results/{i/10:.1f}_features_balanced.pickle', 'wb') as f:\n",
    "    pickle.dump(history, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results from './results/'\n",
    "results = {}\n",
    "for i in range(1, 11):\n",
    "  with open(f'results/{i/10:.1f}_features.pickle', 'rb') as handle:\n",
    "      results[i] = pickle.load(handle)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "11f0019e3984bf9dd420d9c19157658dc02fa04e5bba99878acfb010fb7ecd1e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
